@article{adamopoulou2020chatbots,
  title={Chatbots: History, technology, and applications},
  author={Adamopoulou, Eleni and Moussiades, Lefteris},
  journal={Machine Learning with Applications},
  volume={2},
  year={2020}
}

@article{gu2023mamba,
  title={Mamba: Linear-time sequence modeling with selective state spaces},
  author={Gu, Albert and Dao, Tri},
  journal={arXiv preprint arXiv:2312.00752},
  year={2023}
}

@misc{wikipedia_information_age,
  title={Information Age},
  author={Wikipedia},
  howpublished={\url{https://en.wikipedia.org/wiki/Information_Age}},
  note={Accessed: August 24, 2024}
}

@article{gloeckle2024better,
  title={Better \& Faster Large Language Models via Multi-token Prediction},
  author={Gloeckle, Fabian and Idrissi, Badr Youbi and Rozi{\`e}re, Baptiste and Lopez-Paz, David and Synnaeve, Gabriel},
  journal={arXiv preprint arXiv:2404.19737},
  year={2024}
}

@misc{taylor2023volume,
  author = {P. Taylor},
  title = {Volume of data/information created, captured, copied, and consumed worldwide from 2010 to 2025},
  year = {2023},
  note = {[Online]. Available: \url{https://www.statista.com/statistics/871513/worldwide-data-created/}. [Accessed: Aug. 19, 2024]}
}

@misc{ai_act_website,
  title={Artificial Intelligence Act},
  author={European Commission},
  year={2024},
  url={https://artificialintelligenceact.eu/},
  note={Accessed: August 25, 2024}
}

@article{wu2020towards,
  title={Towards a new generation of artificial intelligence in China},
  author={Wu, Fei and Lu, Cewu and Zhu, Mingjie and Chen, Hao and Zhu, Jun and Yu, Kai and Li, Lei and Li, Ming and Chen, Qianfeng and Li, Xi and others},
  journal={Nature Machine Intelligence},
  volume={2},
  number={6},
  pages={312--316},
  year={2020},
  publisher={Nature Publishing Group UK London}
}

@article{china_ai_plan_2017,
  title={A Next Generation Artificial Intelligence Development Plan},
  author={State Council of the People's Republic of China},
  year={2017},
  journal={Web Archive},
  note={Accessed via Web Archive on August 22, 2024. Available at: \url{https://web.archive.org/web/20220121145209/https://www.mfa.gov.cn/ce/cefi/eng/kxjs/P020171025789108009001.pdf}}
}

@article{cset_ethical_norms_2021,
  title={Ethical Norms for New Generation Artificial Intelligence Released},
  author={Center for Security and Emerging Technology},
  year={2021},
  journal={Center for Security and Emerging Technology},
  note={Available at: \url{https://cset.georgetown.edu/publication/ethical-norms-for-new-generation-artificial-intelligence-released/}}
}

@article{fortune_china_ai_2023,
  title={China’s AI regulations offer blueprint as U.S. races to catch up},
  author={Fortune},
  year={2023},
  journal={Fortune},
  note={Available at: \url{https://fortune.com/2023/07/14/china-ai-regulations-offer-blueprint/}}
}

@online{obama_ai_2016,
  title={The Administration's Report on the Future of Artificial Intelligence},
  author={The White House},
  year={2016},
  url={https://obamawhitehouse.archives.gov/blog/2016/10/12/administrations-report-future-artificial-intelligence},
  note={Accessed: 2024-08-03}
}

@online{nscai_2021,
  title={National Security Commission on Artificial Intelligence},
  author={{National Security Commission on Artificial Intelligence}},
  year={2021},
  url={https://cybercemetery.unt.edu/nscai/20211005220330/https://www.nscai.gov/},
  note={Accessed: 2024-08-03}
}

@incollection{weaver2018regulation,
  title={Regulation of artificial intelligence in the United States},
  author={Weaver, John Frank},
  booktitle={Research Handbook on the Law of Artificial Intelligence},
  pages={155--212},
  year={2018},
  publisher={Edward Elgar Publishing}
}

@article{hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}

@article{towardsdatascience2024lora,
  title={Understanding LoRA: Low-Rank Adaptation for Fine-Tuning Large Models},
  author={{Towards Data Science}},
  journal={Towards Data Science},
  year={2024},
  url={https://towardsdatascience.com/understanding-lora-low-rank-adaptation-for-finetuning-large-models-936bce1a07c6}
}

@inproceedings{shawar2007fostering,
  title={Fostering language learner autonomy through adaptive conversation tutors},
  author={Shawar, Bayan Abu and Atwell, Eric},
  booktitle={Proceedings of the The fourth Corpus Linguistics conference},
  volume={3},
  pages={186--193},
  year={2007}
}

@book{wallace2009anatomy,
  title={The anatomy of ALICE},
  author={Wallace, Richard S},
  year={2009},
  publisher={Springer}
}

@article{shum2018eliza,
  title={From Eliza to XiaoIce: challenges and opportunities with social chatbots},
  author={Shum, Heung-Yeung and He, Xiao-dong and Li, Di},
  journal={Frontiers of Information Technology \& Electronic Engineering},
  volume={19},
  pages={10--26},
  year={2018},
  publisher={Springer}
}

@misc{wikipedia2023cleverbot,
  author = {Wikipedia},
  title = {Cleverbot},
  year = {2023},
  note = {[Online]. Available: \url{https://en.wikipedia.org/wiki/Cleverbot}. [Accessed: August 20, 2024]}
}

@article{chen2016ibm,
  title={IBM Watson: how cognitive computing can be applied to big data challenges in life sciences research},
  author={Chen, Ying and Argentinis, JD Elenee and Weber, Griff},
  journal={Clinical therapeutics},
  volume={38},
  number={4},
  pages={688--701},
  year={2016},
  publisher={Elsevier}
}

@article{zhou2020design,
  title={The design and implementation of xiaoice, an empathetic social chatbot},
  author={Zhou, Li and Gao, Jianfeng and Li, Di and Shum, Heung-Yeung},
  journal={Computational Linguistics},
  volume={46},
  number={1},
  pages={53--93},
  year={2020},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@article{hoy2018alexa,
  title={Alexa, Siri, Cortana, and more: an introduction to voice assistants},
  author={Hoy, Matthew B},
  journal={Medical reference services quarterly},
  volume={37},
  number={1},
  pages={81--88},
  year={2018},
  publisher={Taylor \& Francis}
}

@misc{aron2011innovative,
  title={How innovative is Apple's new voice assistant, Siri?},
  author={Aron, Jacob},
  year={2011},
  publisher={Elsevier}
}

@article{bolton2021security,
  title={On the security and privacy challenges of virtual assistants},
  author={Bolton, Tom and Dargahi, Tooska and Belguith, Sana and Al-Rakhami, Mabrook S and Sodhro, Ali Hassan},
  journal={Sensors},
  volume={21},
  number={7},
  pages={2312},
  year={2021},
  publisher={MDPI}
}

@article{omiye2023large,
  title={Large language models in medicine: the potentials and pitfalls},
  author={Omiye, Jesutofunmi A and Gui, Haiwen and Rezaei, Shawheen J and Zou, James and Daneshjou, Roxana},
  journal={arXiv preprint arXiv:2309.00087},
  year={2023}
}

@article{bommasani2021opportunities,
  title={On the opportunities and risks of foundation models},
  author={Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
  journal={arXiv preprint arXiv:2108.07258},
  year={2021}
}

@article{madotto2021few,
  title={Few-shot bot: Prompt-based learning for dialogue systems},
  author={Madotto, Andrea and Lin, Zhaojiang and Winata, Genta Indra and Fung, Pascale},
  journal={arXiv preprint arXiv:2110.08118},
  year={2021}
}

@article{lester2021power,
  title={The power of scale for parameter-efficient prompt tuning},
  author={Lester, Brian and Al-Rfou, Rami and Constant, Noah},
  journal={arXiv preprint arXiv:2104.08691},
  year={2021}
}

@article{singhal2022large,
  title={Large language models encode clinical knowledge},
  author={Singhal, Karan and Azizi, Shekoofeh and Tu, Tao and Mahdavi, S Sara and Wei, Jason and Chung, Hyung Won and Scales, Nathan and Tanwani, Ajay and Cole-Lewis, Heather and Pfohl, Stephen and others},
  journal={arXiv preprint arXiv:2212.13138},
  year={2022}
}

@article{vu2023freshllms,
  title={Freshllms: Refreshing large language models with search engine augmentation},
  author={Vu, Tu and Iyyer, Mohit and Wang, Xuezhi and Constant, Noah and Wei, Jerry and Wei, Jason and Tar, Chris and Sung, Yun-Hsuan and Zhou, Denny and Le, Quoc and others},
  journal={arXiv preprint arXiv:2310.03214},
  year={2023}
}

@article{wang2023cue,
  title={Cue-CoT: Chain-of-thought prompting for responding to in-depth dialogue questions with LLMs},
  author={Wang, Hongru and Wang, Rui and Mi, Fei and Deng, Yang and Wang, Zezhong and Liang, Bin and Xu, Ruifeng and Wong, Kam-Fai},
  journal={arXiv preprint arXiv:2305.11792},
  year={2023}
}

@article{sawada2023arb,
  title={Arb: Advanced reasoning benchmark for large language models},
  author={Sawada, Tomohiro and Paleka, Daniel and Havrilla, Alexander and Tadepalli, Pranav and Vidas, Paula and Kranias, Alexander and Nay, John J and Gupta, Kshitij and Komatsuzaki, Aran},
  journal={arXiv preprint arXiv:2307.13692},
  year={2023}
}

@article{yin2023survey,
  title={A survey on multimodal large language models},
  author={Yin, Shukang and Fu, Chaoyou and Zhao, Sirui and Li, Ke and Sun, Xing and Xu, Tong and Chen, Enhong},
  journal={arXiv preprint arXiv:2306.13549},
  year={2023}
}

@article{liu2023mmbench,
  title={Mmbench: Is your multi-modal model an all-around player?},
  author={Liu, Yuan and Duan, Haodong and Zhang, Yuanhan and Li, Bo and Zhang, Songyang and Zhao, Wangbo and Yuan, Yike and Wang, Jiaqi and He, Conghui and Liu, Ziwei and others},
  journal={arXiv preprint arXiv:2307.06281},
  year={2023}
}

@article{li2023seed,
  title={Seed-bench: Benchmarking multimodal llms with generative comprehension},
  author={Li, Bohao and Wang, Rui and Wang, Guangzhi and Ge, Yuying and Ge, Yixiao and Shan, Ying},
  journal={arXiv preprint arXiv:2307.16125},
  year={2023}
}

@article{rudin2019stop,
  title={Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead},
  author={Rudin, Cynthia},
  journal={Nature machine intelligence},
  volume={1},
  number={5},
  pages={206--215},
  year={2019},
  publisher={Nature Publishing Group UK London}
}

@article{maynez2020faithfulness,
  title={On faithfulness and factuality in abstractive summarization},
  author={Maynez, Joshua and Narayan, Shashi and Bohnet, Bernd and McDonald, Ryan},
  journal={arXiv preprint arXiv:2005.00661},
  year={2020}
}

@inproceedings{bender2021dangers,
  title={On the dangers of stochastic parrots: Can language models be too big?},
  author={Bender, Emily M and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
  booktitle={Proceedings of the 2021 ACM conference on fairness, accountability, and transparency},
  pages={610--623},
  year={2021}
}

@article{dhingra2022time,
  title={Time-aware language models as temporal knowledge bases},
  author={Dhingra, Bhuwan and Cole, Jeremy R and Eisenschlos, Julian Martin and Gillick, Daniel and Eisenstein, Jacob and Cohen, William W},
  journal={Transactions of the Association for Computational Linguistics},
  volume={10},
  pages={257--273},
  year={2022},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~…}
}

@article{lewis2020retrieval,
  title={Retrieval-augmented generation for knowledge-intensive nlp tasks},
  author={Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9459--9474},
  year={2020}
}

@article{gao2023retrieval,
  title={Retrieval-augmented generation for large language models: A survey},
  author={Gao, Yunfan and Xiong, Yun and Gao, Xinyu and Jia, Kangxiang and Pan, Jinliu and Bi, Yuxi and Dai, Yi and Sun, Jiawei and Wang, Haofen},
  journal={arXiv preprint arXiv:2312.10997},
  year={2023}
}

@inproceedings{chen2024benchmarking,
  title={Benchmarking large language models in retrieval-augmented generation},
  author={Chen, Jiawei and Lin, Hongyu and Han, Xianpei and Sun, Le},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  pages={17754--17762},
  year={2024}
}

@article{liu2023recall,
  title={Recall: A benchmark for llms robustness against external counterfactual knowledge},
  author={Liu, Yi and Huang, Lianzhe and Li, Shicheng and Chen, Sishuo and Zhou, Hao and Meng, Fandong and Zhou, Jie and Sun, Xu},
  journal={arXiv preprint arXiv:2311.08147},
  year={2023}
}

@article{saad2023ares,
  title={Ares: An automated evaluation framework for retrieval-augmented generation systems},
  author={Saad-Falcon, Jon and Khattab, Omar and Potts, Christopher and Zaharia, Matei},
  journal={arXiv preprint arXiv:2311.09476},
  year={2023}
}

@article{chang2024survey,
  title={A survey on evaluation of large language models},
  author={Chang, Yupeng and Wang, Xu and Wang, Jindong and Wu, Yuan and Yang, Linyi and Zhu, Kaijie and Chen, Hao and Yi, Xiaoyuan and Wang, Cunxiang and Wang, Yidong and others},
  journal={ACM Transactions on Intelligent Systems and Technology},
  volume={15},
  number={3},
  pages={1--45},
  year={2024},
  publisher={ACM New York, NY}
}

@inproceedings{guo2017calibration,
  title={On calibration of modern neural networks},
  author={Guo, Chuan and Pleiss, Geoff and Sun, Yu and Weinberger, Kilian Q},
  booktitle={International conference on machine learning},
  pages={1321--1330},
  year={2017},
  organization={PMLR}
}

@article{lin2023llm,
  title={Llm-eval: Unified multi-dimensional automatic evaluation for open-domain conversations with large language models},
  author={Lin, Yen-Ting and Chen, Yun-Nung},
  journal={arXiv preprint arXiv:2305.13711},
  year={2023}
}

@article{wang2023pandalm,
  title={Pandalm: An automatic evaluation benchmark for llm instruction tuning optimization},
  author={Wang, Yidong and Yu, Zhuohao and Zeng, Zhengran and Yang, Linyi and Wang, Cunxiang and Chen, Hao and Jiang, Chaoya and Xie, Rui and Wang, Jindong and Xie, Xing and others},
  journal={arXiv preprint arXiv:2306.05087},
  year={2023}
}

@article{novikova2017we,
  title={Why we need new evaluation metrics for NLG},
  author={Novikova, Jekaterina and Du{\v{s}}ek, Ond{\v{r}}ej and Curry, Amanda Cercas and Rieser, Verena},
  journal={arXiv preprint arXiv:1707.06875},
  year={2017}
}

@article{qin2023chatgpt,
  title={Is ChatGPT a general-purpose natural language processing task solver?},
  author={Qin, Chengwei and Zhang, Aston and Zhang, Zhuosheng and Chen, Jiaao and Yasunaga, Michihiro and Yang, Diyi},
  journal={arXiv preprint arXiv:2302.06476},
  year={2023}
}

@article{bang2023multitask,
  title={A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity},
  author={Bang, Yejin and Cahyawijaya, Samuel and Lee, Nayeon and Dai, Wenliang and Su, Dan and Wilie, Bryan and Lovenia, Holy and Ji, Ziwei and Yu, Tiezheng and Chung, Willy and others},
  journal={arXiv preprint arXiv:2302.04023},
  year={2023}
}

@article{liang2022holistic,
  title={Holistic evaluation of language models},
  author={Liang, Percy and Bommasani, Rishi and Lee, Tony and Tsipras, Dimitris and Soylu, Dilara and Yasunaga, Michihiro and Zhang, Yian and Narayanan, Deepak and Wu, Yuhuai and Kumar, Ananya and others},
  journal={arXiv preprint arXiv:2211.09110},
  year={2022}
}

@article{bai2024benchmarking,
  title={Benchmarking foundation models with language-model-as-an-examiner},
  author={Bai, Yushi and Ying, Jiahao and Cao, Yixin and Lv, Xin and He, Yuze and Wang, Xiaozhi and Yu, Jifan and Zeng, Kaisheng and Xiao, Yijia and Lyu, Haozhe and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{wang2024evaluating,
  title={Evaluating open-qa evaluation},
  author={Wang, Cunxiang and Cheng, Sirui and Guo, Qipeng and Yue, Yuanhao and Ding, Bowen and Xu, Zhikun and Wang, Yidong and Hu, Xiangkun and Zhang, Zheng and Zhang, Yue},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{honovich2022true,
  title={TRUE: Re-evaluating factual consistency evaluation},
  author={Honovich, Or and Aharoni, Roee and Herzig, Jonathan and Taitelbaum, Hagai and Kukliansy, Doron and Cohen, Vered and Scialom, Thomas and Szpektor, Idan and Hassidim, Avinatan and Matias, Yossi},
  journal={arXiv preprint arXiv:2204.04991},
  year={2022}
}

@article{cheng2024lift,
  title={Lift yourself up: Retrieval-augmented text generation with self-memory},
  author={Cheng, Xin and Luo, Di and Chen, Xiuying and Liu, Lemao and Zhao, Dongyan and Yan, Rui},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}


@misc{ibm2023,
  title={How Larger Context Windows Benefit LLMs: New Frontiers in Natural Language Processing},
  author={{IBM Research}},
  year={2023},
  note={\url{https://research.ibm.com/blog/larger-context-window}}
}

@inproceedings{cuconasu2024power,
  title={The power of noise: Redefining retrieval for rag systems},
  author={Cuconasu, Florin and Trappolini, Giovanni and Siciliano, Federico and Filice, Simone and Campagnano, Cesare and Maarek, Yoelle and Tonellotto, Nicola and Silvestri, Fabrizio},
  booktitle={Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={719--729},
  year={2024}
}

@article{lin2023ra,
  title={Ra-dit: Retrieval-augmented dual instruction tuning},
  author={Lin, Xi Victoria and Chen, Xilun and Chen, Mingda and Shi, Weijia and Lomeli, Maria and James, Rich and Rodriguez, Pedro and Kahn, Jacob and Szilvasy, Gergely and Lewis, Mike and others},
  journal={arXiv preprint arXiv:2310.01352},
  year={2023}
}

@article{yan2024corrective,
  title={Corrective retrieval augmented generation},
  author={Yan, Shi-Qi and Gu, Jia-Chen and Zhu, Yun and Ling, Zhen-Hua},
  journal={arXiv preprint arXiv:2401.15884},
  year={2024}
}

@inproceedings{alon2022neuro,
  title={Neuro-symbolic language modeling with automaton-augmented retrieval},
  author={Alon, Uri and Xu, Frank and He, Junxian and Sengupta, Sudipta and Roth, Dan and Neubig, Graham},
  booktitle={International Conference on Machine Learning},
  pages={468--485},
  year={2022},
  organization={PMLR}
}

@inproceedings{papineni2002bleu,
  title={Bleu: a method for automatic evaluation of machine translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle={Proceedings of the 40th annual meeting of the Association for Computational Linguistics},
  pages={311--318},
  year={2002}
}

@inproceedings{lin2004rouge,
  title={Rouge: A package for automatic evaluation of summaries},
  author={Lin, Chin-Yew},
  booktitle={Text summarization branches out},
  pages={74--81},
  year={2004}
}

@article{sulem2018bleu,
  title={BLEU is not suitable for the evaluation of text simplification},
  author={Sulem, Elior and Abend, Omri and Rappoport, Ari},
  journal={arXiv preprint arXiv:1810.05995},
  year={2018}
}

@article{zhang2019bertscore,
  title={Bertscore: Evaluating text generation with bert},
  author={Zhang, Tianyi and Kishore, Varsha and Wu, Felix and Weinberger, Kilian Q and Artzi, Yoav},
  journal={arXiv preprint arXiv:1904.09675},
  year={2019}
}

@article{yuan2021bartscore,
  title={Bartscore: Evaluating generated text as text generation},
  author={Yuan, Weizhe and Neubig, Graham and Liu, Pengfei},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={27263--27277},
  year={2021}
}

@article{es2023ragas,
  title={Ragas: Automated evaluation of retrieval augmented generation},
  author={Es, Shahul and James, Jithin and Espinosa-Anke, Luis and Schockaert, Steven},
  journal={arXiv preprint arXiv:2309.15217},
  year={2023}
}

@article{fu2023gptscore,
  title={Gptscore: Evaluate as you desire},
  author={Fu, Jinlan and Ng, See-Kiong and Jiang, Zhengbao and Liu, Pengfei},
  journal={arXiv preprint arXiv:2302.04166},
  year={2023}
}

@article{he2022blind,
  title={On the blind spots of model-based evaluation metrics for text generation},
  author={He, Tianxing and Zhang, Jingyu and Wang, Tianle and Kumar, Sachin and Cho, Kyunghyun and Glass, James and Tsvetkov, Yulia},
  journal={arXiv preprint arXiv:2212.10020},
  year={2022}
}

@article{sun2022bertscore,
  title={BERTScore is unfair: On social bias in language model-based metrics for text generation},
  author={Sun, Tianxiang and He, Junliang and Qiu, Xipeng and Huang, Xuanjing},
  journal={arXiv preprint arXiv:2210.07626},
  year={2022}
}

@article{gao2024llm,
  title={Llm-based nlg evaluation: Current status and challenges},
  author={Gao, Mingqi and Hu, Xinyu and Ruan, Jie and Pu, Xiao and Wan, Xiaojun},
  journal={arXiv preprint arXiv:2402.01383},
  year={2024}
}

@article{luo2023divide,
  title={Divide \& conquer for entailment-aware multi-hop evidence retrieval},
  author={Luo, Fan and Surdeanu, Mihai},
  journal={arXiv preprint arXiv:2311.02616},
  year={2023}
}

@article{chiang2023can,
  title={Can large language models be an alternative to human evaluations?},
  author={Chiang, Cheng-Han and Lee, Hung-yi},
  journal={arXiv preprint arXiv:2305.01937},
  year={2023}
}

@article{luo2023chatgpt,
  title={Chatgpt as a factual inconsistency evaluator for text summarization},
  author={Luo, Zheheng and Xie, Qianqian and Ananiadou, Sophia},
  journal={arXiv preprint arXiv:2303.15621},
  year={2023}
}

@article{ji2023exploring,
  title={Exploring chatgpt's ability to rank content: A preliminary study on consistency with human preferences},
  author={Ji, Yunjie and Gong, Yan and Peng, Yiping and Ni, Chao and Sun, Peiyan and Pan, Dongyu and Ma, Baochang and Li, Xiangang},
  journal={arXiv preprint arXiv:2303.07610},
  year={2023}
}

@inproceedings{wang2024knowledge,
  title={Knowledge graph prompting for multi-document question answering},
  author={Wang, Yu and Lipka, Nedim and Rossi, Ryan A and Siu, Alexa and Zhang, Ruiyi and Derr, Tyler},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  pages={19206--19214},
  year={2024}
}

@article{arora2023based,
  title={The BASED Architecture: A New Frontier in AI Model Design},
  author={Arora, Zhang},
  journal={HazyResearch Blog},
  year={2023},
  url={https://hazyresearch.stanford.edu/blog/2023-12-11-zoology2-based}
}

@misc{paull2023transformer,
  title={Beyond the Transformer: The Elements of Future AI Architectures},
  author={Paull, Nathan},
  year={2023},
  howpublished={\url{https://nathanpaull.substack.com/p/beyond-the-transformer-the-elements-of-future-ai-architectures-a4acd33cac89}}
}

@article{zhou2022least,
  title={Least-to-most prompting enables complex reasoning in large language models},
  author={Zhou, Denny and Sch{\"a}rli, Nathanael and Hou, Le and Wei, Jason and Scales, Nathan and Wang, Xuezhi and Schuurmans, Dale and Cui, Claire and Bousquet, Olivier and Le, Quoc and others},
  journal={arXiv preprint arXiv:2205.10625},
  year={2022}
}

@article{dhuliawala2023chain,
  title={Chain-of-verification reduces hallucination in large language models},
  author={Dhuliawala, Shehzaad and Komeili, Mojtaba and Xu, Jing and Raileanu, Roberta and Li, Xian and Celikyilmaz, Asli and Weston, Jason},
  journal={arXiv preprint arXiv:2309.11495},
  year={2023}
}

@article{gao2022precise,
  title={Precise zero-shot dense retrieval without relevance labels},
  author={Gao, Luyu and Ma, Xueguang and Lin, Jimmy and Callan, Jamie},
  journal={arXiv preprint arXiv:2212.10496},
  year={2022}
}

@article{zheng2023take,
  title={Take a step back: Evoking reasoning via abstraction in large language models},
  author={Zheng, Huaixiu Steven and Mishra, Swaroop and Chen, Xinyun and Cheng, Heng-Tze and Chi, Ed H and Le, Quoc V and Zhou, Denny},
  journal={arXiv preprint arXiv:2310.06117},
  year={2023}
}

@misc{teja2023chunk,
  title={Evaluating the Ideal Chunk Size for a RAG System Using LlamaIndex},
  author={Teja, R.},
  year={2023},
  note={\url{https://www.llamaindex.ai/blog/evaluating-the-ideal-chunk-size-for-a-rag-system-using-llamaindex-6207e5d3fec5}}
}

@misc{lmsys2024arena,
  title={Chatbot Arena: Benchmarking LLMs in the Wild with Elo Ratings},
  author={{LMSYS}},
  year={2024},
  note={\url{https://lmsys.org}}
}

@misc{langchain2023recursive,
  title={Recursively Split by Character},
  author={Langchain},
  year={2023},
  note={\url{https://python.langchain.com/docs/modules/data_connection/document_transformers/recursive_text_splitter}}
}

@misc{yang2023smalltobig,
  title={Advanced RAG 01: Small-to-Big Retrieval},
  author={Yang, S.},
  year={2023},
  note={\url{https://towardsdatascience.com/advanced-rag-01-small-to-big-retrieval-172181b396d4}}
}

@article{ma2023query,
  title={Query rewriting for retrieval-augmented large language models},
  author={Ma, Xinbei and Gong, Yeyun and He, Pengcheng and Zhao, Hai and Duan, Nan},
  journal={arXiv preprint arXiv:2305.14283},
  year={2023}
}

@article{khattab2022demonstrate,
  title={Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp},
  author={Khattab, Omar and Santhanam, Keshav and Li, Xiang Lisa and Hall, David and Liang, Percy and Potts, Christopher and Zaharia, Matei},
  journal={arXiv preprint arXiv:2212.14024},
  year={2022}
}

@article{li2023classification,
  title={From classification to generation: Insights into crosslingual retrieval augmented icl},
  author={Li, Xiaoqian and Nie, Ercong and Liang, Sheng},
  journal={arXiv preprint arXiv:2311.06595},
  year={2023}
}

@article{yu2022generate,
  title={Generate rather than retrieve: Large language models are strong context generators},
  author={Yu, Wenhao and Iter, Dan and Wang, Shuohang and Xu, Yichong and Ju, Mingxuan and Sanyal, Soumya and Zhu, Chenguang and Zeng, Michael and Jiang, Meng},
  journal={arXiv preprint arXiv:2209.10063},
  year={2022}
}

@article{cheng2023uprise,
  title={Uprise: Universal prompt retrieval for improving zero-shot evaluation},
  author={Cheng, Daixuan and Huang, Shaohan and Bi, Junyu and Zhan, Yuefeng and Liu, Jianfeng and Wang, Yujing and Sun, Hao and Wei, Furu and Deng, Denvy and Zhang, Qi},
  journal={arXiv preprint arXiv:2303.08518},
  year={2023}
}

@article{liu2024lost,
  title={Lost in the middle: How language models use long contexts},
  author={Liu, Nelson F and Lin, Kevin and Hewitt, John and Paranjape, Ashwin and Bevilacqua, Michele and Petroni, Fabio and Liang, Percy},
  journal={Transactions of the Association for Computational Linguistics},
  volume={12},
  pages={157--173},
  year={2024},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~…}
}

@article{gao2023chat,
  title={Chat-rec: Towards interactive and explainable llms-augmented recommender system},
  author={Gao, Yunfan and Sheng, Tao and Xiang, Youlin and Xiong, Yun and Wang, Haofen and Zhang, Jiawei},
  journal={arXiv preprint arXiv:2303.14524},
  year={2023}
}

@article{cui2023chatlaw,
  title={Chatlaw: Open-source legal large language model with integrated external knowledge bases},
  author={Cui, Jiaxi and Li, Zongjian and Yan, Yang and Chen, Bohua and Yuan, Li},
  journal={arXiv preprint arXiv:2306.16092},
  year={2023}
}

@article{du2022retrieval,
  title={Retrieval-augmented generative question answering for event argument extraction},
  author={Du, Xinya and Ji, Heng},
  journal={arXiv preprint arXiv:2211.07067},
  year={2022}
}

@article{shi2023dual,
  title={Dual-feedback knowledge retrieval for task-oriented dialogue systems},
  author={Shi, Tianyuan and Li, Liangzhi and Lin, Zijian and Yang, Tao and Quan, Xiaojun and Wang, Qifan},
  journal={arXiv preprint arXiv:2310.14528},
  year={2023}
}

@article{yoran2023making,
  title={Making retrieval-augmented language models robust to irrelevant context},
  author={Yoran, Ori and Wolfson, Tomer and Ram, Ori and Berant, Jonathan},
  journal={arXiv preprint arXiv:2310.01558},
  year={2023}
}

@article{asai2023self,
  title={Self-rag: Learning to retrieve, generate, and critique through self-reflection},
  author={Asai, Akari and Wu, Zeqiu and Wang, Yizhong and Sil, Avirup and Hajishirzi, Hannaneh},
  journal={arXiv preprint arXiv:2310.11511},
  year={2023}
}

@article{zha2023tablegpt,
  title={Tablegpt: Towards unifying tables, nature language and commands into one gpt},
  author={Zha, Liangyu and Zhou, Junlin and Li, Liyao and Wang, Rui and Huang, Qingyi and Yang, Saisai and Yuan, Jing and Su, Changbao and Li, Xiang and Su, Aofeng and others},
  journal={arXiv preprint arXiv:2307.08674},
  year={2023}
}

@article{luo2023augmented,
  title={Augmented large language models with parametric knowledge guiding},
  author={Luo, Ziyang and Xu, Can and Zhao, Pu and Geng, Xiubo and Tao, Chongyang and Ma, Jing and Lin, Qingwei and Jiang, Daxin},
  journal={arXiv preprint arXiv:2305.04757},
  year={2023}
}

@article{he2024g,
  title={G-retriever: Retrieval-augmented generation for textual graph understanding and question answering},
  author={He, Xiaoxin and Tian, Yijun and Sun, Yifei and Chawla, Nitesh V and Laurent, Thomas and LeCun, Yann and Bresson, Xavier and Hooi, Bryan},
  journal={arXiv preprint arXiv:2402.07630},
  year={2024}
}

@article{arora2023gar,
  title={Gar-meets-rag paradigm for zero-shot information retrieval},
  author={Arora, Daman and Kini, Anush and Chowdhury, Sayak Ray and Natarajan, Nagarajan and Sinha, Gaurav and Sharma, Amit},
  journal={arXiv preprint arXiv:2310.20158},
  year={2023}
}

@inproceedings{borgeaud2022improving,
  title={Improving language models by retrieving from trillions of tokens},
  author={Borgeaud, Sebastian and Mensch, Arthur and Hoffmann, Jordan and Cai, Trevor and Rutherford, Eliza and Millican, Katie and Van Den Driessche, George Bm and Lespiau, Jean-Baptiste and Damoc, Bogdan and Clark, Aidan and others},
  booktitle={International conference on machine learning},
  pages={2206--2240},
  year={2022},
  organization={PMLR}
}

@article{wang2023knowledgpt,
  title={Knowledgpt: Enhancing large language models with retrieval and storage access on knowledge bases},
  author={Wang, Xintao and Yang, Qianwen and Qiu, Yongting and Liang, Jiaqing and He, Qianyu and Gu, Zhouhong and Xiao, Yanghua and Wang, Wei},
  journal={arXiv preprint arXiv:2308.11761},
  year={2023}
}

@article{wang2022generalizing,
  title={Generalizing to unseen domains: A survey on domain generalization},
  author={Wang, Jindong and Lan, Cuiling and Liu, Chang and Ouyang, Yidong and Qin, Tao and Lu, Wang and Chen, Yiqiang and Zeng, Wenjun and Philip, S Yu},
  journal={IEEE transactions on knowledge and data engineering},
  volume={35},
  number={8},
  pages={8052--8072},
  year={2022},
  publisher={IEEE}
}

@article{yang2022glue,
  title={Glue-x: Evaluating natural language understanding models from an out-of-distribution generalization perspective},
  author={Yang, Linyi and Zhang, Shuibai and Qin, Libo and Li, Yafu and Wang, Yidong and Liu, Hanmeng and Wang, Jindong and Xie, Xing and Zhang, Yue},
  journal={arXiv preprint arXiv:2211.08073},
  year={2022}
}

@article{zhu2023promptbench,
  title={Promptbench: Towards evaluating the robustness of large language models on adversarial prompts},
  author={Zhu, Kaijie and Wang, Jindong and Zhou, Jiaheng and Wang, Zichen and Chen, Hao and Wang, Yidong and Yang, Linyi and Ye, Wei and Zhang, Yue and Gong, Neil Zhenqiang and others},
  journal={arXiv preprint arXiv:2306.04528},
  year={2023}
}

@inproceedings{molnar2020interpretable,
  title={Interpretable machine learning--a brief history, state-of-the-art and challenges},
  author={Molnar, Christoph and Casalicchio, Giuseppe and Bischl, Bernd},
  booktitle={Joint European conference on machine learning and knowledge discovery in databases},
  pages={417--431},
  year={2020},
  organization={Springer}
}

@article{huang2022overview,
  title={An overview of artificial intelligence ethics},
  author={Huang, Changwu and Zhang, Zeqi and Mao, Bifei and Yao, Xin},
  journal={IEEE Transactions on Artificial Intelligence},
  volume={4},
  number={4},
  pages={799--819},
  year={2022},
  publisher={IEEE}
}

@inproceedings{dilmaghani2019privacy,
  title={Privacy and security of big data in AI systems: A research and standards perspective},
  author={Dilmaghani, Saharnaz and Brust, Matthias R and Danoy, Gr{\'e}goire and Cassagnes, Natalia and Pecero, Johnatan and Bouvry, Pascal},
  booktitle={2019 IEEE international conference on big data (big data)},
  pages={5737--5743},
  year={2019},
  organization={IEEE}
}

@article{sullins2011robot,
  title={When is a robot a moral agent},
  author={Sullins, John P},
  journal={Machine ethics},
  volume={6},
  number={2001},
  pages={151--161},
  year={2011},
  publisher={Cambridge University Press Cambridge}
}

@inproceedings{timmermans2010ethics,
  title={The ethics of cloud computing: A conceptual review},
  author={Timmermans, Job and Stahl, Bernd Carsten and Ikonen, Veikko and Bozdag, Engin},
  booktitle={2010 IEEE second international conference on cloud computing technology and science},
  pages={614--620},
  year={2010},
  organization={IEEE}
}

@inproceedings{wang2023decodingtrust,
  title={DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT Models.},
  author={Wang, Boxin and Chen, Weixin and Pei, Hengzhi and Xie, Chulin and Kang, Mintong and Zhang, Chenhui and Xu, Chejian and Xiong, Zidi and Dutta, Ritik and Schaeffer, Rylan and others},
  booktitle={NeurIPS},
  year={2023}
}

@article{zhuo2023red,
  title={Red teaming chatgpt via jailbreaking: Bias, robustness, reliability and toxicity},
  author={Zhuo, Terry Yue and Huang, Yujin and Chen, Chunyang and Xing, Zhenchang},
  journal={arXiv preprint arXiv:2301.12867},
  year={2023}
}

@article{deshpande2023toxicity,
  title={Toxicity in chatgpt: Analyzing persona-assigned language models},
  author={Deshpande, Ameet and Murahari, Vishvak and Rajpurohit, Tanmay and Kalyan, Ashwin and Narasimhan, Karthik},
  journal={arXiv preprint arXiv:2304.05335},
  year={2023}
}

@article{wang2023large,
  title={Large language models are not fair evaluators},
  author={Wang, Peiyi and Li, Lei and Chen, Liang and Cai, Zefan and Zhu, Dawei and Lin, Binghuai and Cao, Yunbo and Liu, Qi and Liu, Tianyu and Sui, Zhifang},
  journal={arXiv preprint arXiv:2305.17926},
  year={2023}
}

@article{lu2023emergent,
  title={Are Emergent Abilities in Large Language Models just In-Context Learning?},
  author={Lu, Sheng and Bigoulaeva, Irina and Sachdeva, Rachneet and Madabushi, Harish Tayyar and Gurevych, Iryna},
  journal={arXiv preprint arXiv:2309.01809},
  year={2023}
}

@misc{bath2024ai,
  title={AI poses no existential threat to humanity, new study finds},
  author={{University of Bath}},
  year={2024},
  howpublished={\url{https://www.bath.ac.uk/announcements/ai-poses-no-existential-threat-to-humanity-new-study-finds/}},
}

@misc{aiprm2023chatgpt,
  title={Top 10 ChatGPT Statistics},
  author={{AIPRM}},
  year={2023},
  howpublished={\url{https://www.aiprm.com/chatgpt-statistics/#top-10-chatgpt-statistics}},
  note={Accessed: 2024-08-04}
}

@article{wu2023brief,
  title={A brief overview of ChatGPT: The history, status quo and potential future development},
  author={Wu, Tianyu and He, Shizhu and Liu, Jingping and Sun, Siqi and Liu, Kang and Han, Qing-Long and Tang, Yang},
  journal={IEEE/CAA Journal of Automatica Sinica},
  volume={10},
  number={5},
  pages={1122--1136},
  year={2023},
  publisher={IEEE}
}

@misc{ragfusion2023,
  title={Forget RAG, The Future is RAG Fusion},
  author={Towards Data Science},
  year={2023},
  note={\url{https://medium.com/towards-data-science/forget-rag-the-future-is-rag-fusion-1147298d8ad1}}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@article{bai2022constitutional,
  title={Constitutional ai: Harmlessness from ai feedback},
  author={Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and others},
  journal={arXiv preprint arXiv:2212.08073},
  year={2022}
}

@misc{ilin2023advancedrag,
  title={Advanced RAG Techniques: An Illustrated Overview},
  author={Ilin, I.},
  year={2023},
  note={\url{https://pub.towardsai.net/advanced-rag-techniques-an-illustrated-overview-04d193d8fec6}}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{howard2018universal,
  title={Universal language model fine-tuning for text classification},
  author={Howard, Jeremy and Ruder, Sebastian},
  journal={arXiv preprint arXiv:1801.06146},
  year={2018}
}

@inproceedings{ro2021autolr,
  title={Autolr: Layer-wise pruning and auto-tuning of learning rates in fine-tuning of deep networks},
  author={Ro, Youngmin and Choi, Jin Young},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  pages={2486--2494},
  year={2021}
}

@inproceedings{houlsby2019parameter,
  title={Parameter-efficient transfer learning for NLP},
  author={Houlsby, Neil and Giurgiu, Andrei and Jastrzebski, Stanislaw and Morrone, Bruna and De Laroussilhe, Quentin and Gesmundo, Andrea and Attariyan, Mona and Gelly, Sylvain},
  booktitle={International conference on machine learning},
  pages={2790--2799},
  year={2019},
  organization={PMLR}
}

@article{han2024parameter,
  title={Parameter-efficient fine-tuning for large models: A comprehensive survey},
  author={Han, Zeyu and Gao, Chao and Liu, Jinyang and Zhang, Sai Qian and others},
  journal={arXiv preprint arXiv:2403.14608},
  year={2024}
}

@inproceedings{bang2015example,
  title={Example-based chat-oriented dialogue system with personalized long-term memory},
  author={Bang, Jeesoo and Noh, Hyungjong and Kim, Yonghee and Lee, Gary Geunbae},
  booktitle={2015 International Conference on Big Data and Smart Computing (BIGCOMP)},
  pages={238--243},
  organization={IEEE},
  year={2015}
}

@misc{lin2021truthfulqa,
  title={TruthfulQA: Measuring how models mimic human falsehoods},
  author={Lin, Stephanie and Hilton, Jacob and Evans, Owain},
  year={2021},
  note={arXiv preprint arXiv:2109.07958}
}

@article{weizenbaum1966eliza,
  title={ELIZA—a computer program for the study of natural language communication between man and machine},
  author={Weizenbaum, Joseph},
  journal={Communications of the ACM},
  volume={9},
  number={1},
  pages={36--45},
  year={1966},
  publisher={ACM New York, NY, USA}
}

@article{zimmerman2023human,
  title={Human/AI relationships: challenges, downsides, and impacts on human/human relationships},
  author={Zimmerman, Anne and Janhonen, Joel and Beer, Emily},
  journal={AI and Ethics},
  pages={1--13},
  year={2023},
  publisher={Springer}
}

@article{colby1971artificial,
  title={Artificial paranoia},
  author={Colby, Kenneth Mark and Weber, Sylvia and Hilf, Franklin Dennis},
  journal={Artificial intelligence},
  volume={2},
  number={1},
  pages={1--25},
  year={1971},
  publisher={Elsevier}
}

@article{escudeiro2008,
    author = {Escudeiro, Paula and Bidarra, José},
    year = {2008},
    month = {01},
    pages = {16},
    title = {Quantitative Evaluation Framework (QEF)},
    journal = {Conselho Editorial/Consejo Editorial}
}

@misc{createwithswift2024,
  author = {Create with Swift},
  title = {Prototyping SwiftUI Interfaces with OpenAI’s ChatGPT},
  year = {2024},
  howpublished = {\url{https://www.createwithswift.com/prototyping-swiftui-interfaces-with-openais-chatgpt/}},
  note = {Accessed: August 26, 2024}
}

@misc{wikipedia2023racter,
  author = {{Wikipedia}},
  title = {{Racter}},
  year = {2023},
  note = {[Online]. Available: \url{https://en.wikipedia.org/wiki/Racter}}
}

@article{winograd1972understanding,
  title={Understanding natural language},
  author={Winograd, Terry},
  journal={Cognitive psychology},
  volume={3},
  number={1},
  pages={1--191},
  year={1972},
  publisher={Elsevier}
}

@misc{researchgraph2024,
  author = {ResearchGraph},
  title = {Brief Introduction to the History of Large Language Models (LLMs)},
  year = {2024},
  howpublished = {\url{https://medium.com/@researchgraph/brief-introduction-to-the-history-of-large-language-models-llms-3c2efa517112}}
}

@article{elman1990finding,
  title={Finding structure in time},
  author={Elman, Jeffrey L},
  journal={Cognitive science},
  volume={14},
  number={2},
  pages={179--211},
  year={1990},
  publisher={Wiley Online Library}
}

@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT press}
}

@article{cho2014learning,
  title={Learning phrase representations using RNN encoder-decoder for statistical machine translation},
  author={Cho, Kyunghyun and Van Merri{\"e}nboer, Bart and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1406.1078},
  year={2014}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}

@article{yang2019xlnet,
  title={Xlnet: Generalized autoregressive pretraining for language understanding},
  author={Yang, Zhilin and Dai, Zihang and Yang, Yiming and Carbonell, Jaime and Salakhutdinov, Russ R and Le, Quoc V},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{park2019,
    author = {Park, Dongju and Ahn, Chang Wook},
    year = {2019},
    month = {11},
    pages = {1393},
    title = {Self-Supervised Contextual Data Augmentation for Natural Language Processing},
    volume = {11},
    journal = {Symmetry},
    doi = {10.3390/sym11111393}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{lewis2019bart,
  title={Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension},
  author={Lewis, Mike and Liu, Yinhan and Goyal, Naman and Ghazvininejad, Marjan and Mohamed, Abdelrahman and Levy, Omer and Stoyanov, Ves and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:1910.13461},
  year={2019}
}

@article{radford2018improving,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya and others},
  year={2018},
  journal={OpenAI blog},
  publisher={San Francisco, CA, USA}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@misc{geeksforgeeks2024-pe,
  title={Positional Encoding in Transformers},
  author={GeeksforGeeks},
  howpublished={\url{https://www.geeksforgeeks.org/positional-encoding-in-transformers/}},
  year={2024},
  note={Accessed: 2024-07-28}
}

@misc{geeksforgeeks2024-sa,
  title={Self-Attention in NLP},
  author={{GeeksforGeeks}},
  year={2023},
  howpublished={\url{https://www.geeksforgeeks.org/self-attention-in-nlp/}},
  note={Accessed: 2024-07-28}
}

@article{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={Ieee}
}

@misc{epoch2024trackinglargescaleaimodels,
  title={Tracking Large-Scale AI Models},
  author={Robi Rahman and David Owen and Josh You},
  year={2024},
  url={https://epochai.org/blog/tracking-large-scale-ai-models},
  note={Accessed: 2024-08-02}
}

@misc{epoch2024trainingcomputeoffrontieraimodelsgrowsby45xperyear,
  title={Training Compute of Frontier AI Models Grows by 4-5x per Year},
  author={Jaime Sevilla and Edu Roldán},
  year={2024},
  url={https://epochai.org/blog/training-compute-of-frontier-ai-models-grows-by-4-5x-per-year},
  note={Accessed: 2024-08-02}
}

@article{maslej2024ai,
  title={The AI Index 2024 Annual Report},
  author={Maslej, Nestor and Fattorini, Loredana and Perrault, Raymond and Parli, Vanessa and Reuel, Anka and Brynjolfsson, Erik and Etchemendy, John and Ligett, Katrina and Lyons, Terah and Manyika, James and Niebles, Juan Carlos and Shoham, Yoav and Wald, Russell and Clark, Jack},
  journal={AI Index Steering Committee, Institute for Human-Centered AI, Stanford University, Stanford, CA},
  year={2024},
  month={April}
}

@article{berryhill2019hello,
  title={Hello, World: Artificial intelligence and its use in the public sector},
  author={Berryhill, Jamie and Heang, K{\'e}vin Kok and Clogher, Rob and McBride, Keegan},
  year={2019},
  journal={OECD},
  publisher={OECD}
}

@article{allen2023race,
  title={The Race to Regulate Artificial Intelligence},
  author={Allen, John R. and West, Alexander},
  year={2023},
  journal={Foreign Affairs},
  url={https://www.foreignaffairs.com/united-states/race-regulate-artificial-intelligence},
  note={Accessed: August 24, 2024}
}

@article{cepr_gdpr_2023,
  title={Regulatory Export and Spillovers: How GDPR Affects Global Markets for Data},
  author={VoxEU},
  year={2023},
  journal={VoxEU},
  url={https://cepr.org/voxeu/columns/regulatory-export-and-spillovers-how-gdpr-affects-global-markets-data},
  note={Accessed: August 25, 2024}
}

@misc{eu_trustworthy_ai_2019,
  title={Ethics Guidelines for Trustworthy AI},
  author={European Commission},
  year={2019},
  url={https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai},
  note={Accessed: August 25, 2024}
}

@misc{eu_ai_investment_2019,
  title={Policy and Investment Recommendations for Trustworthy Artificial Intelligence},
  author={European Commission},
  year={2019},
  url={https://digital-strategy.ec.europa.eu/en/library/policy-and-investment-recommendations-trustworthy-artificial-intelligence},
  note={Accessed: August 25, 2024}
}

@article{nyt_europe_ai_regulation_2023,
  title={Europe’s Move Toward Strict AI Regulation Could Be a Global Turning Point},
  author={Kantrowitz, Alex and MacCarthy, Mark},
  journal={The New York Times},
  year={2023},
  month={June},
  day={14},
  url={https://www.nytimes.com/2023/06/14/technology/europe-ai-regulation.html},
  note={Accessed: August 25, 2024}
}

@misc{eu_white_paper_ai_2020,
  title={White Paper on Artificial Intelligence: A European approach to excellence and trust},
  author={European Commission},
  year={2020},
  month={February},
  url={https://digital-strategy.ec.europa.eu/en/consultations/white-paper-artificial-intelligence-european-approach-excellence-and-trust},
  note={Accessed: August 25, 2024}
}

@misc{mhc_regulating_ai_2023,
  title={Regulating AI in the EU},
  author={Mason Hayes & Curran LLP},
  year={2023},
  month={July},
  url={https://www.mhc.ie/latest/insights/regulating-ai-in-the-eu},
  note={Accessed: August 25, 2024}
}

@article{simonyan2014very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{dam2024complete,
  title={A Complete Survey on LLM-based AI Chatbots},
  author={Dam, Sumit Kumar and Hong, Choong Seon and Qiao, Yu and Zhang, Chaoning},
  journal={arXiv preprint arXiv:2406.16937},
  year={2024}
}

@misc{googletrends2023,
  author = {{Google Trends}},
  title = {Trends Comparison: ChatGPT, 5G, AI, Blockchain, Bitcoin},
  year = {2023},
  note = {[Online]. Available: \url{https://trends.google.com/trends/explore?date=today%205-y&q=ChatGPT,5G,AI,Blockchain,Bitcoin&hl=en}. [Accessed: Aug. 19, 2024]}
}

@article{lo2023impact,
  title={What is the impact of ChatGPT on education? A rapid review of the literature},
  author={Lo, Chung Kwan},
  journal={Education Sciences},
  volume={13},
  number={4},
  pages={410},
  year={2023},
  publisher={MDPI}
}

@book{turing2009computing,
  title={Computing machinery and intelligence},
  author={Turing, Alan M},
  year={2009},
  publisher={Springer}
}

@article{koubaa2023exploring,
  title={Exploring ChatGPT capabilities and limitations: a survey},
  author={Koubaa, Anis and Boulila, Wadii and Ghouti, Lahouari and Alzahem, Ayyub and Latif, Shahid},
  journal={IEEE Access},
  year={2023},
  publisher={IEEE}
}

@inproceedings{bahrini2023chatgpt,
  title={ChatGPT: Applications, opportunities, and threats},
  author={Bahrini, Aram and Khamoshifar, Mohammadsadra and Abbasimehr, Hossein and Riggs, Robert J and Esmaeili, Maryam and Majdabadkohne, Rastin Mastali and Pasehvar, Morteza},
  booktitle={2023 Systems and Information Engineering Design Symposium (SIEDS)},
  pages={274--279},
  year={2023},
  organization={IEEE}
}

@article{zhang2023one,
  title={One small step for generative ai, one giant leap for agi: A complete survey on chatgpt in aigc era},
  author={Zhang, Chaoning and Zhang, Chenshuang and Li, Chenghao and Qiao, Yu and Zheng, Sheng and Dam, Sumit Kumar and Zhang, Mengchun and Kim, Jung Uk and Kim, Seong Tae and Choi, Jinwoo and others},
  journal={arXiv preprint arXiv:2304.06488},
  year={2023}
}

@article{villalobos2022machine,
  title={Machine learning model sizes and the parameter gap},
  author={Villalobos, Pablo and Sevilla, Jaime and Besiroglu, Tamay and Heim, Lennart and Ho, Anson and Hobbhahn, Marius},
  journal={arXiv preprint arXiv:2207.02852},
  year={2022}
}

@article{wei2022emergent,
  title={Emergent abilities of large language models},
  author={Wei, Jason and Tay, Yi and Bommasani, Rishi and Raffel, Colin and Zoph, Barret and Borgeaud, Sebastian and Yogatama, Dani and Bosma, Maarten and Zhou, Denny and Metzler, Donald and others},
  journal={arXiv preprint arXiv:2206.07682},
  year={2022}
}

@misc{wikipedia2023chatgpt,
  author = {{Wikipedia}},
  title = {{ChatGPT}},
  year = {2023},
  note = {[Online]. Available: \url{https://en.wikipedia.org/wiki/ChatGPT}. [Accessed: Aug. 20, 2024]}
}

@misc{wikipedia2023gemini,
  author = {{Wikipedia}},
  title = {{Gemini (chatbot)}},
  year = {2023},
  note = {[Online]. Available: \url{https://en.wikipedia.org/wiki/Gemini_(chatbot)}. [Accessed: Aug. 20, 2024]}
}

@misc{aljazeera2023chatgpt,
  author = {A. Jazeera},
  title = {{ChatGPT can now browse the internet for updated information}},
  year = {2023},
  note = {[Online]. Available: \url{https://www.aljazeera.com/news/2023/9/28/chatgpt-can-now-browse-the-internet-for-updated-information}}
}

@inproceedings{pascanu2013difficulty,
  title={On the difficulty of training recurrent neural networks},
  author={Pascanu, Razvan and Mikolov, Tomas and Bengio, Yoshua},
  booktitle={International conference on machine learning},
  pages={1310--1318},
  year={2013},
  organization={Pmlr}
}

@article{ba2016layer,
  title={Layer normalization},
  author={Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E},
  journal={arXiv preprint arXiv:1607.06450},
  year={2016}
}

@misc{eliza_wikipedia,
    author = {Wikipedia contributors},
    title = {ELIZA --- Wikipedia},
    year = {2024},
    url = {https://en.wikipedia.org/wiki/ELIZA},
    note = {[Online; accessed 26-August-2024]}
}

@misc{microsoft2024copilot,
  author = {Microsoft},
  title = {{Copilot}},
  year = {2024},
  note = {[Online]. Available: \url{https://copilot.microsoft.com/}}
}

@misc{wikipedia2023copilot,
  author = {Wikipedia},
  title = {Microsoft Copilot},
  year = {2023},
  note = {[Online]. Available: \url{https://en.wikipedia.org/wiki/Microsoft_Copilot}. [Accessed: Aug. 20, 2024]}
}

@misc{wikipedia2024anthropic,
  author = {{Wikipedia}},
  title = {{Anthropic}},
  year = {2024},
  url = {https://en.wikipedia.org/wiki/Anthropic},
  note = {[Accessed: Aug. 20, 2024]}
}

@article{motlagh2023impact,
  title={The impact of artificial intelligence on the evolution of digital education: A comparative study of openAI text generation tools including ChatGPT, Bing Chat, Bard, and Ernie},
  author={Motlagh, Negin Yazdani and Khajavi, Matin and Sharifi, Abbas and Ahmadi, Mohsen},
  journal={arXiv preprint arXiv:2309.02029},
  year={2023}
}

@misc{yang2023baidu,
  author = {Z. Yang},
  title = {Chinese tech giant Baidu just released its answer to ChatGPT},
  year = {2023},
  note = {[Online]. Available: \url{https://www.technologyreview.com/2023/03/16/1069919/baidu-ernie-bot-chatgpt-launch/}. [Accessed: Aug. 20, 2024]}
}

@misc{rodriguez2023sparrow,
  author = {J. Rodriguez},
  title = {Inside Sparrow: The foundation of DeepMind’s ChatGPT alternative},
  year = {2023},
  note = {[Online]. Available: \url{https://jrodthoughts.medium.com/inside-sparrow-the-foundation-of-deepminds-chatgpt-alternative-854df43569fd}. [Accessed: Aug. 20, 2024]}
}

@article{vasconcelos2023enhancing,
  title={Enhancing STEM learning with ChatGPT and Bing Chat as objects to think with: A case study},
  author={Vasconcelos, Marco Antonio Rodrigues and Santos, Renato P dos},
  journal={arXiv preprint arXiv:2305.02202},
  year={2023}
}

@article{khan2023harnessing,
  title={Harnessing GPT-4 so that all students benefit},
  author={Khan, Sal},
  journal={A nonprofit approach for equal access. Khan Academy. URL: https://blog. khanacademy. org/harnessing-ai-so-that-allstudents-benefit-a-nonprofit-approach-for-equal-access},
  year={2023}
}

@misc{Duolingo2023,
  author = {{Duolingo Team}},
  title = {Introducing Duolingo Max, a learning experience powered by GPT-4},
  year = {2023},
  url = {https://blog.duolingo.com/duolingo-max/},
  note = {[Online; accessed Aug. 20, 2024]}
}

@misc{wikipedia2024grok,
  author = {Wikipedia},
  title = {Grok (chatbot)},
  year = {2024},
  note = {[Online]. Available: \url{https://en.wikipedia.org/wiki/Grok_(chatbot)}. [Accessed: Aug. 20, 2024]}
}

@article{chandha2023setting,
  title={Setting the Scene: How Artificial Intelligence is reshaping how we consume and deliver research},
  author={Chandha, Saikiran and Sucheth, R and Ghosal, Tirthankar},
  journal={Upstream},
  year={2023}
}

@misc{jiang2023,
  author = {Y. Jiang},
  title = {LLM-based Financial Analytics Chatbot},
  year = {2023},
  url = {https://www.linkedin.com/pulse/llm-based-financialanalytics-chatbot-yicheng-jiang/},
  note = {[Online; accessed Aug. 20, 2024]}
}

@article{temsah2023reflection,
  title={Reflection with ChatGPT about the excess death after the COVID-19 pandemic},
  author={Temsah, Mohamad-Hani and Jamal, Amr and Al-Tawfiq, Jaffar A},
  year={2023},
  journal={scholarworks.iupui.edu},
  publisher={Elsevier}
}

@article{gilson2023does,
  title={How does ChatGPT perform on the United States Medical Licensing Examination (USMLE)? The implications of large language models for medical education and knowledge assessment},
  author={Gilson, Aidan and Safranek, Conrad W and Huang, Thomas and Socrates, Vimig and Chi, Ling and Taylor, Richard Andrew and Chartash, David and others},
  journal={JMIR medical education},
  volume={9},
  number={1},
  pages={e45312},
  year={2023},
  publisher={JMIR Publications Inc., Toronto, Canada}
}

@article{hamidi2023evaluation,
  title={Evaluation of AI chatbots for patient-specific EHR questions},
  author={Hamidi, Alaleh and Roberts, Kirk},
  journal={arXiv preprint arXiv:2306.02549},
  year={2023}
}

@misc{leung2023,
  author = {K. Leung},
  title = {Macy the AI Pharmacist!},
  year = {2023},
  url = {https://www.linkedin.com/posts/kennethleungty-generativeai-aipharmacist-activity-7031533843429949440-pVZb/},
  note = {[Online; accessed Aug. 20, 2024]}
}

@article{chen2023use,
  title={Use of artificial intelligence chatbots for cancer treatment information},
  author={Chen, Shan and Kann, Benjamin H and Foote, Michael B and Aerts, Hugo JWL and Savova, Guergana K and Mak, Raymond H and Bitterman, Danielle S},
  journal={JAMA oncology},
  volume={9},
  number={10},
  pages={1459--1462},
  year={2023},
  publisher={American Medical Association}
}

@article{meyer2023chatgpt,
  title={ChatGPT and large language models in academia: opportunities and challenges},
  author={Meyer, Jesse G and Urbanowicz, Ryan J and Martin, Patrick CN and O’Connor, Karen and Li, Ruowang and Peng, Pei-Chen and Bright, Tiffani J and Tatonetti, Nicholas and Won, Kyoung Jae and Gonzalez-Hernandez, Graciela and others},
  journal={BioData Mining},
  volume={16},
  number={1},
  pages={20},
  year={2023},
  publisher={Springer}
}

@article{dowling2023chatgpt,
  title={ChatGPT for (finance) research: The Bananarama conjecture},
  author={Dowling, Michael and Lucey, Brian},
  journal={Finance Research Letters},
  volume={53},
  pages={103662},
  year={2023},
  publisher={Elsevier}
}

@misc{reuters_eu_ai_rules_2023,
  title={What are the EU's landmark AI rules?},
  author={Reuters},
  year={2023},
  month={December},
  url={https://www.reuters.com/technology/what-are-eus-landmark-ai-rules-2023-12-06/},
  note={Accessed: August 25, 2024}
}

@misc{atlantic_council_eu_ai_rules_2023,
  title={Experts React: The EU made a deal on AI rules. But can regulators move at the speed of tech?},
  author={Atlantic Council},
  year={2023},
  month={December},
  url={https://www.atlanticcouncil.org/blogs/new-atlanticist/experts-react/experts-react-the-eu-made-a-deal-on-ai-rules-but-can-regulators-move-at-the-speed-of-tech/},
  note={Accessed: August 25, 2024}
}

@misc{wikipedia_ai_regulation,
  title={Regulation of artificial intelligence},
  author={Wikipedia contributors},
  year={2024},
  url={https://en.wikipedia.org/wiki/Regulation_of_artificial_intelligence},
  note={Accessed: August 25, 2024}
}

@online{ai_bill_of_rights_2022,
  title={Blueprint for an AI Bill of Rights},
  author={The White House Office of Science and Technology Policy (OSTP)},
  year={2022},
  url={https://www.whitehouse.gov/ostp/ai-bill-of-rights/},
  note={Accessed: 2024-08-03}
}

@online{executive_order_maintaining_ai_leadership_2019,
  title={Executive Order on Maintaining American Leadership in Artificial Intelligence},
  author={The White House},
  year={2019},
  url={https://trumpwhitehouse.archives.gov/presidential-actions/executive-order-maintaining-american-leadership-artificial-intelligence/},
  note={Accessed: 2024-08-03}
}

@online{omb_memo_regulation_ai_2020,
  title={Draft OMB Memo on Regulation of Artificial Intelligence},
  author={The White House Office of Management and Budget},
  year={2020},
  url={https://www.whitehouse.gov/wp-content/uploads/2020/01/Draft-OMB-Memo-on-Regulation-of-AI-1-7-19.pdf},
  note={Accessed: 2024-08-03}
}

@online{biden_executive_order_ai_2023,
  title={Fact Sheet: President Biden Issues Executive Order on Safe, Secure, and Trustworthy Artificial Intelligence},
  author={The White House},
  year={2023},
  url={https://www.whitehouse.gov/briefing-room/statements-releases/2023/10/30/fact-sheet-president-biden-issues-executive-order-on-safe-secure-and-trustworthy-artificial-intelligence/},
  note={Accessed: 2024-08-03}
}

@article{altan2023science,
  title={Science Fiction to Real Life: Bing AI as An Investment Advisor},
  author={Altan, {\.I}nci Merve and K{\i}l{\i}{\c{c}}, Metin},
  journal={Ekonomi {\.I}{\c{s}}letme ve Y{\"o}netim Dergisi},
  volume={7},
  number={2},
  pages={240--260},
  year={2023},
  publisher={Karabuk University}
}

@inproceedings{kim2015acquisition,
  title={Acquisition and use of long-term memory for personalized dialog systems},
  author={Kim, Yonghee and Bang, Jeesoo and Choi, Junhwi and Ryu, Seonghan and Koo, Sangjun and Lee, Gary Geunbae},
  booktitle={Multimodal Analyses enabling Artificial Agents in Human-Machine Interaction: Second International Workshop, MA3HMI 2014, Held in Conjunction with INTERSPEECH 2014, Singapore, Singapore, September 14, 2014, Revised Selected Papers 2},
  pages={78--87},
  year={2015},
  organization={Springer}
}

@article{shumanov2021making,
  title={Making conversations with chatbots more personalized},
  author={Shumanov, Michael and Johnson, Lester},
  journal={Computers in Human Behavior},
  volume={117},
  pages={106627},
  year={2021},
  publisher={Elsevier}
}

@article{koga2024evaluating,
  title={Evaluating the performance of large language models: ChatGPT and Google Bard in generating differential diagnoses in clinicopathological conferences of neurodegenerative disorders},
  author={Koga, Shunsuke and Martin, Nicholas B and Dickson, Dennis W},
  journal={Brain Pathology},
  volume={34},
  number={3},
  pages={e13207},
  year={2024},
  publisher={Wiley Online Library}
}

@article{zhao2023survey,
  title={A survey of large language models},
  author={Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and others},
  journal={arXiv preprint arXiv:2303.18223},
  year={2023}
}

@article{li2023transformer,
  title={Transformer for object detection: Review and benchmark},
  author={Li, Yong and Miao, Naipeng and Ma, Liangdi and Shuang, Feng and Huang, Xingwen},
  journal={Engineering Applications of Artificial Intelligence},
  volume={126},
  pages={107021},
  year={2023},
  publisher={Elsevier}
}

@article{kazemnejad2019:pencoding,
  title   = "Transformer Architecture: The Positional Encoding",
  author  = "Kazemnejad, Amirhossein",
  journal = "kazemnejad.com",
  year    = "2019",
  url     = "https://kazemnejad.com/blog/transformer_architecture_positional_encoding/"
}

@article{chowdhery2023palm,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={Journal of Machine Learning Research},
  volume={24},
  number={240},
  pages={1--113},
  year={2023}
}

@article{team2023gemini,
  title={Gemini: a family of highly capable multimodal models},
  author={Team, Gemini and Anil, Rohan and Borgeaud, Sebastian and Wu, Yonghui and Alayrac, Jean-Baptiste and Yu, Jiahui and Soricut, Radu and Schalkwyk, Johan and Dai, Andrew M and Hauth, Anja and others},
  journal={arXiv preprint arXiv:2312.11805},
  year={2023}
}

@article{li2023collaborative,
  title={Collaborative Evaluation: Exploring the Synergy of Large Language Models and Humans for Open-ended Generation Evaluation},
  author={Li, Qintong and Cui, Leyang and Kong, Lingpeng and Bi, Wei},
  journal={arXiv preprint arXiv:2310.19740},
  year={2023}
}

@inproceedings{zhang2021human,
  title={A human-machine collaborative framework for evaluating malevolence in dialogues},
  author={Zhang, Yangjun and Ren, Pengjie and de Rijke, Maarten},
  booktitle={Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  pages={5612--5623},
  year={2021}
}

@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@article{jozefowicz2016exploring,
  title={Exploring the limits of language modeling},
  author={Jozefowicz, Rafal and Vinyals, Oriol and Schuster, Mike and Shazeer, Noam and Wu, Yonghui},
  journal={arXiv preprint arXiv:1602.02410},
  year={2016}
}

@article{bahdanau2014neural,
  title={Neural machine translation by jointly learning to align and translate},
  author={Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1409.0473},
  year={2014}
}

@article{anthropic2024claude,
  title={The claude 3 model family: Opus, sonnet, haiku},
  author={Anthropic, AI},
  journal={Claude-3 Model Card},
  volume={1},
  year={2024}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{verma2023generative,
  title={Generative AI as a Tool for Enhancing Customer Relationship Management Automation and Personalization Techniques},
  author={Verma, Ramesh Kumar and Kumari, Nalini},
  journal={International Journal of Responsible Artificial Intelligence},
  volume={13},
  number={9},
  pages={1--8},
  year={2023}
}

@misc{wang2018glue,
  title={GLUE: A multi-task benchmark and analysis platform for natural language understanding},
  author={Wang, Alex and others},
  year={2018},
  note={arXiv preprint arXiv:1804.07461}
}

@misc{hpa2024,
  title={HPA - High Performance Analytics},
  author={HPA},
  year={2024},
  note={\url{https://www.hpa.ai/}}
}

@misc{terranova2024,
  title={Terranova Software},
  author={{Terranova Software}},
  year={2024},
  note={\url{https://www.terranovasoftware.eu/en}}
}

@misc{langchain2024,
  title={LangChain},
  author={{LangChain}},
  year={2024},
  note={\url{https://www.langchain.com/}}
}

@article{dorri2018multi,
  title={Multi-agent systems: A survey},
  author={Dorri, Ali and Kanhere, Salil S and Jurdak, Raja},
  journal={Ieee Access},
  volume={6},
  pages={28573--28593},
  year={2018},
  publisher={IEEE}
}

@article{sanh2019distilbert,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author={Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
  journal={arXiv preprint arXiv:1910.01108},
  year={2019}
}

@article{abdullah2021multilingual,
  title={Multilingual Sentiment Analysis: A Systematic Literature Review.},
  author={Abdullah, Nur Atiqah Sia and Rusli, Nur Ida Aniza},
  journal={Pertanika Journal of Science \& Technology},
  volume={29},
  number={1},
  year={2021}
}

@article{wu2022survey,
  title={A survey of human-in-the-loop for machine learning},
  author={Wu, Xingjiao and Xiao, Luwei and Sun, Yixuan and Zhang, Junhang and Ma, Tianlong and He, Liang},
  journal={Future Generation Computer Systems},
  volume={135},
  pages={364--381},
  year={2022},
  publisher={Elsevier}
}

@article{jiao2019tinybert,
  title={Tinybert: Distilling bert for natural language understanding},
  author={Jiao, Xiaoqi and Yin, Yichun and Shang, Lifeng and Jiang, Xin and Chen, Xiao and Li, Linlin and Wang, Fang and Liu, Qun},
  journal={arXiv preprint arXiv:1909.10351},
  year={2019}
}

@article{lan2019albert,
  title={Albert: A lite bert for self-supervised learning of language representations},
  author={Lan, Zhenzhong and Chen, Mingda and Goodman, Sebastian and Gimpel, Kevin and Sharma, Piyush and Soricut, Radu},
  journal={arXiv preprint arXiv:1909.11942},
  year={2019}
}

@article{ferrara2023fairness,
  title={Fairness and bias in artificial intelligence: A brief survey of sources, impacts, and mitigation strategies},
  author={Ferrara, Emilio},
  journal={Sci},
  volume={6},
  number={1},
  pages={3},
  year={2023},
  publisher={MDPI}
}

@inproceedings{zheng2024judging,
  title={Judging LLM-as-a-judge with MT-Bench and chatbot arena},
  author={Zheng, Lianmin and others},
  booktitle={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{kiela2021dynabench,
  title={Dynabench: Rethinking benchmarking in NLP},
  author={Kiela, Douwe and Bartolo, Max and Nie, Yixin and Kaushik, Divyansh and Geiger, Atticus and Wu, Zhengxuan and Vidgen, Bertie and Prasad, Grusha and Singh, Amanpreet and Ringshia, Pratik and others},
  journal={arXiv preprint arXiv:2104.14337},
  year={2021}
}

@article{liu2023g,
  title={G-eval: Nlg evaluation using gpt-4 with better human alignment},
  author={Liu, Yang and Iter, Dan and Xu, Yichong and Wang, Shuohang and Xu, Ruochen and Zhu, Chenguang},
  journal={arXiv preprint arXiv:2303.16634},
  year={2023}
}

@article{wu2023style,
  title={Style over substance: Evaluation biases for large language models},
  author={Wu, Minghao and Aji, Alham Fikri},
  journal={arXiv preprint arXiv:2307.03025},
  year={2023}
}

@article{hada2023large,
  title={Are large language model-based evaluators the solution to scaling up multilingual evaluation?},
  author={Hada, Rishav and Gumma, Varun and de Wynter, Adrian and Diddee, Harshita and Ahmed, Mohamed and Choudhury, Monojit and Bali, Kalika and Sitaram, Sunayana},
  journal={arXiv preprint arXiv:2309.07462},
  year={2023}
}

@inproceedings{eddine2022frugalscore,
  title={FrugalScore: Learning cheaper, lighter and faster evaluation metrics for automatic text generation},
  author={Eddine, Moussa Kamal and Shang, Guokan and Tixier, Antoine and Vazirgiannis, Michalis},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={1305--1318},
  year={2022}
}
